{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "\n",
    "# Create a local StreamingContext with two working thread and batch interval of user given seconds\n",
    "sc = SparkContext(appName=\"LocationsStream\")\n",
    "ssc = StreamingContext(sc, 5)\n",
    "ssc.checkpoint(\"mentions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MOST = 5\n",
    "C_VAR = 10**-6\n",
    "\n",
    "def quiet_logging(context):\n",
    "    logger = sc._jvm.org.apache.log4j\n",
    "    logger.LogManager.getLogger(\"org\"). setLevel( logger.Level.ERROR )\n",
    "    logger.LogManager.getLogger(\"akka\").setLevel( logger.Level.ERROR )\n",
    "\n",
    "def decayingWindow(incoming_stream, prev_stream):\n",
    "    # First iterations, we add the whole stream as an empty array and a count of 0 elements\n",
    "    if prev_stream == None:\n",
    "        prev_stream = [[], []]\n",
    "\n",
    "    # Sample is the array of the previous stream\n",
    "    distinct_elems = set(incoming_stream)\n",
    "\n",
    "    sample_values = []\n",
    "    sample_weights = []\n",
    "\n",
    "    # Iterate every new user on the stream, calculate weights for each\n",
    "    for elem in distinct_elems:\n",
    "        count = 1 if incoming_stream[0] == elem else 0\n",
    "\n",
    "        for inc_elem_idx in range(len(incoming_stream)):\n",
    "            if inc_elem_idx == 0: \n",
    "                count = (count) * (1-C_VAR)\n",
    "                continue\n",
    "        \n",
    "            count = (count) * (1-C_VAR) + (1 if elem == incoming_stream[inc_elem_idx] else 0)\n",
    "\n",
    "        if elem not in sample_values:\n",
    "            sample_values.append(elem)\n",
    "            sample_weights.append(count)\n",
    "        else:\n",
    "            idx = sample_values.index(elem)\n",
    "            sample_weights[idx] += count\n",
    "    \n",
    "    return [sample_values,sample_weights]\n",
    "\n",
    "def getOrderedCounts(rdd):\n",
    "    # We grab the two lists, and then map them into a better struct (value, weight)\n",
    "    counts_dict = rdd.map(lambda x: x[1]) \\\n",
    "            .map(lambda x: [(x[0][i], x[1][i]) for i in range(len(x[0]))]) \\\n",
    "            .flatMap(lambda x: x)\n",
    "    \n",
    "    ordered_dict = counts_dict.sortBy(lambda x: x[1],ascending=False)\n",
    "    return ordered_dict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Most popular N\n",
    "\n",
    "    quiet_logging(sc)\n",
    "\n",
    "    lines = ssc.socketTextStream(\"localhost\", 9999)\n",
    "\n",
    "    # Split each line into pairs (timestamp, event)\n",
    "    pairs = lines.map(lambda line: line.split(\" \")[1].split(\",\"))\n",
    "\n",
    "    pre_sampled_data = pairs.map(lambda mention: (0, mention[1])) \\\n",
    "\n",
    "    sampled_data = pre_sampled_data.updateStateByKey(decayingWindow)\n",
    "\n",
    "    ordered_counts = sampled_data.transform(getOrderedCounts)\n",
    "\n",
    "    ordered_counts.pprint(N_MOST)\n",
    "\n",
    "    ssc.start()\n",
    "    ssc.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "third-mdle-assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
