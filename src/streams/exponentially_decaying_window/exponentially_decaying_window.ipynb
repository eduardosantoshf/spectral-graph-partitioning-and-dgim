{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n",
    "sc = SparkContext(appName = \"ExponentiallyDecayingWindow\")\n",
    "\n",
    "batch_interval = 5 # batch interval of user given seconds\n",
    "\n",
    "ssc = StreamingContext(sc, batch_interval)\n",
    "ssc.checkpoint(\"events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10 ** -6 # decay factor\n",
    "\n",
    "def quiet_logging(context):\n",
    "    logger = sc._jvm.org.apache.log4j\n",
    "    logger.LogManager.getLogger(\"org\"). setLevel( logger.Level.ERROR )\n",
    "    logger.LogManager.getLogger(\"akka\").setLevel( logger.Level.ERROR )\n",
    "\n",
    "def decaying_window(incoming_stream, previous_stream):\n",
    "    # we add the whole stream as an empty array and a count of 0 elements\n",
    "    if previous_stream == None:\n",
    "        previous_stream = [[], []]\n",
    "\n",
    "    # get the distinct elements in the incoming stream\n",
    "    distinct_elems = set(incoming_stream)\n",
    "\n",
    "    sample_values = []\n",
    "    sample_weights = []\n",
    "\n",
    "    # iterate every new user on the stream, calculate weights for each one\n",
    "    for elem in distinct_elems:\n",
    "        count = 1 if incoming_stream[0] == elem else 0\n",
    "\n",
    "        # calculate the weight for the current element in the stream\n",
    "        for inc_elem_idx in range(len(incoming_stream)):\n",
    "            if inc_elem_idx == 0: \n",
    "                # apply the decay factor for the first element\n",
    "                count = count * (1 - C) \n",
    "\n",
    "                continue\n",
    "            \n",
    "            bit = 1 if elem == incoming_stream[inc_elem_idx] else 0\n",
    "\n",
    "            # calculate the weighted count using the decay factor and the matching bit\n",
    "            count = count * (1 - C) + bit\n",
    "\n",
    "        # add the element and its corresponding weight to the sample lists\n",
    "        if elem not in sample_values:\n",
    "            sample_values.append(elem)\n",
    "            sample_weights.append(round(count))\n",
    "        else:\n",
    "            idx = sample_values.index(elem)\n",
    "            # update the weight if the element already exists in the samples\n",
    "            sample_weights[idx] += round(count)\n",
    "    \n",
    "    return [sample_values, sample_weights]\n",
    "\n",
    "def get_ordered_counts(rdd):\n",
    "    # map the two lists into a better struct: (value, weight)\n",
    "    counts_dict = rdd.map(lambda x: x[1]) \\\n",
    "            .map(lambda x: [(x[0][i], x[1][i]) for i in range(len(x[0]))]) \\\n",
    "            .flatMap(lambda x: x)\n",
    "    \n",
    "    ordered_dict = counts_dict.sortBy(lambda x: x[1], ascending = False)\n",
    "\n",
    "    return ordered_dict\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    quiet_logging(sc)\n",
    "\n",
    "    # Create a DStream by reading from a socket\n",
    "    lines = ssc.socketTextStream(\"localhost\", 9999)\n",
    "\n",
    "    # split each line into pairs (timestamp, event)\n",
    "    pairs = lines.map(lambda line: line.split(\" \")[1].split(\",\"))\n",
    "\n",
    "    # map each pair to (0, event) for initial state \n",
    "    pre_sampled_data = pairs.map(lambda mention: (0, mention[1])) \\\n",
    "\n",
    "    # update the state of the DStream using decaying_window function\n",
    "    sampled_data = pre_sampled_data.updateStateByKey(decaying_window)\n",
    "\n",
    "    ordered_counts = sampled_data.transform(get_ordered_counts)\n",
    "\n",
    "    ordered_counts.pprint(5) # print the 5 most frequent events\n",
    "\n",
    "    ssc.start()\n",
    "    ssc.awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "third-mdle-assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
